## 1.1 操作系统的概念、功能和目标
### 操作系统的概念（定义）

- 操作系统是指控制和管理整个计算机系统的硬件和软件资源，并合理地组织调度计算机的工作和资源的分配，以提供给用户和其他软件方便的接口和环境，它是计算机系统中最基本的**系统软件**。
### 操作系统的功能和目标

- 作为系统资源的管理者（目标：安全、高效） 
   - 文件管理
   - 存储器管理
   - 处理机管理
   - 设备管理
- 作为用户和计算机硬件之间的接口（目标：方便用户使用） 
   - 命令接口（允许用户直接使用） 
      - 联机命令接口（用户说一句，系统做一句）（命令提示符cmd）
      - 脱机命令借口（用户说一堆，系统做一堆）（批处理命令接口.bat）
   - 程序接口（允许用户通过程序间接使用）（.dll文件） 
      - 由一组系统调用组成
   - GUI（图形用户界面）
- 作为最接近硬件的层次（目标：实现对硬件机器对拓展）
### 总结
![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230208142128165.png#id=E5NIW&originHeight=738&originWidth=1340&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
## 1.2 操作系统的特征
### 操作系统的特征

- 并发 
   - 两个或多个事件在同一**时间间隔**内发生。宏观上是同时发生，但微观上是交替发生（并行：两个或多个事件在**同一时刻**同时发生）
   - 操作系统的**并发性**指计算机系统中同时存在着多个运行的程序。
- 共享 
   - 共享即资源共享，是指系统中的资源可供内存中多个并发执行的进程共同使用
   - 互斥共享方式：一个时间段内只允许一个进程访问该资源（摄像头）
   - 同时共享方式：允许一个时间段内由多个进程“同时”对它进行访问
- 虚拟 
   - 虚拟是把一个物理上存在的实体变为若干个逻辑上的对应物。
   - 虚拟存储器技术。“空分复用技术”
   - 虚拟处理器技术。“时分复用技术”
- 异步 
   - 在多道程序环境下，允许多个程序并发执行，但是由于资源有限，进程的执行并不是一贯到底的，而是走走停停，以不可预知的速度向前推进的，这就是进程的异步性。
- 并发和共享**互为存在条件**
- 并发和共享是操作系统**最基本**的两个特征
### 总结
![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230208142036620.png#id=XcZXw&originHeight=587&originWidth=1228&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
## 1.3 操作系统的发展和分类

- 手工操作阶段 
   - 主要缺点：用户独占全机、人机速度矛盾导致资源利用率极低
- 批处理阶段——单道批处理系统 
   - 引入**脱机输入/输出技术**（用磁带完成），并由**监督程序**（操作系统的雏形）负责控制作业的输入输出
   - 主要优点：缓解了一定程度的人际速度矛盾，资源的利用率有所提升。
   - 主要缺点：内存中仅能**有一道程序运行**，只有该程序运行结束之后才能调入下一道程序。CPU有大量时间是空闲在**等待I/O完成**。
- 批处理阶段——多道批处理系统 
   - 操作系统正式诞生，引入了中断技术，各个程序**并发执行**。
   - 主要优点：多道程序**并发**执行，**共享**计算机资源。资源利用率大幅提升，CPU和其他资源保持“忙碌”状态，系统吞吐量增大。
   - 主要缺点：用户响应时间长，没有人机交互功能（用户提交自己的作业后，只能等待计算机处理完成，中间不能控制自己的作业执行）。
- 分时操作系统 
   - 计算机以**时间片**为单位**轮流为各个用户/作业服务**，各个用户可通过终端与计算机交互。
   - 主要优点：用户的请求可以被及时响应，**解决了人机交互问题**，允许多个用户同时使用一台计算机，并且用户对计算机的操作相互独立。
   - 主要缺点：**不能优先处理一些紧急任务**，操作系统对各个用户/作业都是完全公平的。
- 实时操作系统 
   - 主要优点：能够优先响应一些紧急任务，某些紧急任务不需要时间片排队
   - 在实时操作系统的控制下，计算机系统接收到外部信号后及时进行处理，并且**要在严格的时限内处理完事件**。实时操作系统的主要特点是**及时性**和**可靠性**。
   - 硬实时系统：必须在绝对严格的规定时间内完成处理。
   - 软实时系统：能接受偶尔违反时间规定
### 总结
![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230208141937157.png#id=oHcaP&originHeight=735&originWidth=1337&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
## 1.4 操作系统的运行机制和体系结构
### 指令

- 处理器（CPU）能识别、执行的最基本命令 
   - **特权指令**：如内存清零指令
   - **非特权指令**：如普通的运算指令
### 两种处理状态

- **用户态**（目态）（此时CPU只能执行非特权指令）（用程序状态字寄存器（PSW）中的某标志位来标识）
- **核心态**（管态）（特权、非特权指令都可以执行）
### 两种程序

- **内核程序**（操作系统的内核程序是系统的管理者，特权非特权指令都可以执行，**运行在核心态**）
- **应用程序**（为保证系统能安全运行，普通应用程序只能执行非特权指令，**运行在用户态**）
### **内核**

- 内核是计算机上配置的底层**软件**，是操作系统最基本、最核心的部分，实现操作系统内核功能的那些程序就是内核程序 
   - 时钟管理：实现计时功能
   - 中断处理：负责实现中断机制
   - 原语 
      - 是一种特殊的程序
      - 处于操作系统的最底层，最接近硬件的部分
      - 这种程序的运行具有**原子性**——其运行只能一气呵成，不可中断
      - 运行时间较短、调用频繁
   - 对系统资源进行管理的功能： 
      - 进程管理
      - 存储器管理
      - 设备管理
### 操作系统的体系结构

- 大内核 
   - 将操作系统的主要功能模块都作为系统内核，运行在核心态
   - 优点：高性能
   - 缺点：内核代码庞大，结构混乱，难以维护
- 微内核 
   - 只把最基本的功能保留在内核
   - 优点：内核功能少，结构清晰，方便维护
   - 缺点：需要频繁地在核心态和用户态之间切换，性能低
### 总结
![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230208141901959.png#id=ZLHXJ&originHeight=754&originWidth=1495&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
## 1.5 中断和异常
### 中断机制的诞生

- 早期的计算机，各程序只能串行执行，系统资源利用率低
- 为解决上述问题，人们发明了操作系统，引入中断机制，实现多道程序并发执行
- 本质：**发生中断**就意味着**需要操作系统介入，开展管理工作**
- CPU收到计时部件发出的中断信号，切换至核心态，对中断信号进行处理
### 中断的概念和作用

- 当中断发生时，CPU立即进入**核心态**
- 当中断发生后，当前运行的进程会暂停运行，并由操作系统内核对中断进行处理
- 对于不同的中断信号，会进行不同的处理
- **中断**可以使CPU**从用户态切换为核心态**，使操作系统获得计算机的控制权。有了中断，才能实现多道程序并发执行。
- **“用户态 -> 核心态”**是通过中断实现的，并且中断是**唯一途径**。
- **“核心态 -> 用户态”**的切换时**通过执行一个特权指令**，将程序状态字（PSW）的标志位设置为“用户态”。
### 中断的分类

-  **内中断**（也称**异常**、例外、陷入）（信号来自CPU**内部**，与当前执行的指令**有关**） 
   - 自愿中断——指令中断（如：系统调用时使用的**访管指令，又叫陷入指令、trap指令**）
   - 强迫中断 
      - 硬件故障（如：缺页）
      - 软件中断（如：整数除0）
-  **外中断**（也称中断，狭义上的中断）（信号来自CPU**外部**，与当前执行的指令**无关**） 
   - 外设请求（如：I/O操作完成发出的中断信号）
   - 人工干预（如：用户强制终止一个进程）

或

-  **内中断（内部异常）** 
   - 陷阱、陷入（trap）（有意而为之的异常，如系统调用）
   - 故障（fault）（由错误条件引起的，可能被故障处理程序修复，如：缺页）
   - 终止（abort）（不可恢复的致命错误，终止的程序不在返回给应用程序，如整数除0）
-  **外中断**（也称中断） 
   - I/O请求
   - 人工干预
### 外中断的处理过程

- 执行完每个指令之后，CPU都要检查当前是否有外部中断信号
- 如果检测到外部中断信号，则需要保护被中断进程的CPU环境（如程序状态字PSw、程序计数器PC、各种通用寄存器)
- 根据中断信号类型转入相应的中断处理程序
- 恢复原进程的CPU环境并退出中断，返回原进程继续往下执行
### 总结
![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230208141813515.png#id=HtIgv&originHeight=748&originWidth=1266&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
## 1.6 系统调用
### 什么是系统调用，有何作用

-  “系统调用”是操作系统提供给应用程序（程序员/编程人员）使用的接口，可以理解为一种可供应用程序调用的特殊函数，应用程序可以发出系统调用请求来获得操作系统的服务。 
-  应用程序通过**系统调用**请求操作系统的服务。系统中的各种共享资源都由操作系统统一掌管，因此在用户程序中，凡是与资源有关的操作（如存储分配、I/O操作、文件管理等），都必须通过系统调用的方式向操作系统提出请求，由操作系统代为完成。 
-  这样可以**保证系统的稳定性和安全性**，防止用户进行非法操作。 
-  系统调用的相关处理需要在**核心态**进行，所以系统调用会使处理器**从用户态进入核心态** 
-  分类：（凡是和资源有关的操作、会直接影响到其他进程的操作，需要通过系统调用实现） 
   - 设备管理
   - 文件管理
   - 进程控制
   - 进程通信
   - 内存管理
### 系统调用和库函数的区别

- 系统调用是操作系统向上层提供的接口
- 有的库函数是对系统调用的进一步封装
- 当今编写的应用程序大多是通过高级语言提供的库函数间接地进行系统调用
### 系统调用背后的过程

- 传递系统调用参数
- 执行陷入指令**（用户态）**
- 执行系统调用相应的服务程序**（核心态）**
- 返回用户程序
### 总结
![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230208141725016.png#id=xoAmM&originHeight=745&originWidth=1341&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
## 2.1.1 进程的定义、组成、组织方式、特征
### 进程的定义

-  程序：一个指令序列，分为程序段、数据段 
-  系统为每个运行的程序配置了一个数据结构，称为**进程控制块（PCB）**，用来描述进程的各种信息（如程序代码存放位置） 
-  **程序段、数据段、PCB**三部分组成了**进程实体（进程映像）**。一般情况 下，我们把进程实体就简称为进程，例如，所谓创建进程，实质上就是创建进程实体中的PCB；而撤销进程，实质上就是撤销进程实体中的PCB。 
-  **PCB是进程的唯一标志。** 
-  定义： 
   - 进程是程序的一次**执行过程**。
   - 进程是一个程序及其数据在处理及上顺序执行时所**发生的活动**。
   - 进程是具有独立功能的程序在数据集合上**运行的过程**，它是系统进行资源分配和调度的一个独立单位。
   - **进程**是进程实体的**运行过程**，是系统进行**资源分配**和**调度**的一个独立单位。
   - 进程实体是**静态的**，进程是**动态的**。但是除非题目专门考察二者的区别，否则可以认为进程实体就是进程。
### 进程的组成

- PCB**（进程管理者（操作系统）所需的数据都在PCB中）** 
   - 进程描述信息 
      - 进程标识符PID
      - 用户标识符UID
   - 进程控制和管理信息 
      - 进程当前状态
      - 进程优先级
   - 资源分配清单 
      - 程序段指针
      - 数据段指针
      - 键盘
      - 鼠标
   - 处理机相关信息 
      - 各种寄存器值
- 程序段**（程序本身的运行所需的数据）** 
   - 存放要执行的代码
- 数据段**（程序本身的运行所需的数据）** 
   - 存放程序运行过程中处理的各种数据
### 进程的组织

- 链接方式 
   - 按照进程状态将PCB分为多个队列
   - 操作系统持有指向各个队列的指针
- 索引方式 
   - 根据进程状态的不同，建立几张索引表
   - 操作系统持有指向各个索引表的指针
### 进程的特征

- 动态性：进程是程序的一次执行过程，是动态地产生、变化和消亡的（**最基本的特征**）
- 并发性：内存中有多个进程实体，各进程可并发执行
- 独立性：进程是**能独立运行、独立获得资源、独立接受调度的基本单位**
- 异步性：各进程按各自独立的、不可预知的速度向前推进，操作系统要提供“进程同步机制”来解决异步问题
- 结构性：每个进程都会配置一个PCB。从结构上看，进程由程序段、数据段和PCB组成。
### 总结
![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230208141638376.png#id=s4kKU&originHeight=781&originWidth=1326&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
## 2.1.2 进程的状态与转换
### 进程的状态——三种基本状态

- 运行态：占有CPU，并在CPU上运行 
   - 单核处理机环境下，每一个时刻最多只有一个进程处于运行态（双核则是两个）
- 就绪态：已经具备运行条件，但是由于没有空闲CPU，而暂时不能运行 
   - 进程已经拥有除了处理机以外的所有需要的资源
- 阻塞态（等待态）：因等待某一事件而暂时不能运行 
   - 如等待操作系统分配打印机、等待读磁盘操作的结果等
- 创建态：进程正在被创建，操作系统为进程分配资源、初始化PCB
- 终止态：进程正在从系统中撤销，操作系统会回收进程拥有的资源、撤销PCB
### 进程状态的转换
![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230207230416777.png#id=sfEk6&originHeight=711&originWidth=1466&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
### 总结
![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230208141553065.png#id=et1El&originHeight=723&originWidth=1362&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
## 2.1.3 进程控制
### 什么是进程控制

-  进程控制的主要功能是对系统中的所有进程实施有效的管理，它具有**创建新进程、撤销已有进程、实现进程状态转换**等功能。 
-  用**原语**实现进程控制。原语的特点是**执行期间不允许中断**，只能一气呵成。这种不可中断的操作即**原子操作**。 
-  原语采用“**关中断指令**”和**“开中断指令**”实现，这些是只允许在**核心态**下执行的**特权指令** 
### 进程控制相关的原语

- 更新PCB中的信息 
   - 所有进程控制原语一定都会修改进程状态标志
   - 剥夺当前运行进程的CPU使用权必然需要保存其运行环境
   - 某进程开始运行前必然要恢复运行环境
- 将PCB插入合适的队列
- 分配/回收资源
- 创建
- 终止
- 阻塞
- 唤醒
- 切换
### 总结
![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230208141505166.png#id=q0Z3M&originHeight=642&originWidth=1399&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
## 2.1.4 进程通信
### 什么是进程通信

- 进程通信就是指进程之间的信息交换
- 进程是分配系统资源的单位（包括内存地址空间），因此各进程拥有的内存地址空间相互独立
- 一个进程不能直接访问另一个进程的地址空间
- 分类 
   - 共享存储
   - 消息传递
   - 管道通信
### 共享存储
![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230208140255548.png#id=nnw9Y&originHeight=573&originWidth=1012&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)

- 两个进程对共享空间的**访问必须是互斥**的（(互斥访问通过操作系统提供的工具实现）。
- 操作系统只负责提供共享空间和同步互斥工具（如P、V操作)
- **基于数据结构的共享:** 
   - 比如共享空间里只能放一个长度为10的数组。这种共享方式速度慢、限制多，是一种**低级通信**方式
- **基于存储区的共享:** 
   - 在内存中画出一块共享存储区，数据的形式、存放位置都由进程控制，而不是操作系统。
   - 相比之下，这种共享方式速度更快，是一种**高级通信**方式。
### 管道通信
![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230208140558492.png#id=StRot&originHeight=282&originWidth=1287&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)

-  管道只能采用**半双工通信**，某一时间段内只能实现单向的传输。如果要**实现双向同时通信，则需要设置两个管道**。 
-  各进程要**互斥 **地访问管道。 
-  数据以字符流的形式写入管道，当**管道写满**时，**写进程**的write()系统调用将被**阻塞**，等待读进程将数据取走。当读进程将数据全部取走后，**管道变空**，此时**读进程**的read()系统调用将被**阻塞**。 
-  如果**没写满，就不允许读**。如果**没读空，就不允许写**。 
-  数据一旦被读出，就从管道中被抛弃，这就意味着**读进程最多只能有一个**，否则可能会有读错数据的情况。 
### 消息传递

- 进程间的数据交换以**格式化的消息**（Message）为单位。进程通过操作系统提供的**“发送消息/接收消息”两个原语**进行数据交换。
- 消息分为**消息头，消息体**。消息头包括**：发送进程ID、接收进程ID、消息类型、消息长度等格式化的信息**（计算机网络中的“报文”）
- 消息传递分类： 
   - 直接通信方式：消息直接挂到接收进程的消息缓冲队列中 
      - ![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230208141211640.png#id=Gyw8r&originHeight=355&originWidth=554&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
   - 间接通信方式：先发到中间实体（信箱）中，也成为“信箱通信方式”。 
      - ![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230208141321676.png#id=D4cI6&originHeight=286&originWidth=764&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)

### 总结
![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230208141427505.png#id=WWWYb&originHeight=747&originWidth=1129&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
## 2.1.5 线程概念和多线程模型
### 什么是线程
![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230208142628889.png#id=lhSXG&originHeight=520&originWidth=1412&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)

- 可以把线程理解为“轻量级进程”。
- **线程**是一个**基本的CPU执行单元**,也是**程序执行流的最小单位**。
- 引入线程之后，不仅是**进程之间可以并发**，进程内的**各线程之间也可以并发**，从而进一步提升了系统的并发度，使得一个进程内也可以并发处理各种任务（如QQ视频、文字聊天、传文件)
- 引入线程后，**进程只作为除CPU之外的系统资源的分配单元**（如打印机、内存地址空间等都是分配给进程的）。
### 引入线程机制之后，有什么变化

- 资源分配、调度： 
   - 传统进程机制中，进程是资源分配、调度的基本单位
   - 引入线程之后，进程是资源分配的基本单位，线程是调度的基本单位
- 并发性： 
   - 传统进程机制中，只能进程之间并发
   - 引入线程后，各线程之间也能并发，提高了并发度
- 系统开销： 
   - 传统的进程间并发，需要切换进程的运行环境，系统开销很大
   - 线程间并发，如果是同一线程内的线程切换，不需要切换进程环境，系统开销小
   - 引入线程后，并发所带来的开销减小
### 线程的属性

- **线程**是处理机**调度的单位**
- 多CPU计算机中，各个**线程可占用不同的CPU**
- 每个线程都有一**个线程ID**、**线程控制块(TCB)**
- 线程也有**就绪、阻塞、运行**三种基本状态
- 线程几乎**不拥有系统资源**
- 同一进程的不同线程间**共享进程的资源**
- 由于**共享内存地址空间**，同一进程中的线程间**通信甚至无需系统干预**
- **同一**进程中的线程切换，**不会**引起**进程切换**
- **不同**进程中的线程切换，**会**引起**进程切换**
- **切换同进程**内的**线程**，系统**开销很小**
- **切换进程**，系统**开销较大**
### 线程的实现方式

-  用户级线程 
   - ![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230208144009206.png#id=IbKb4&originHeight=574&originWidth=701&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
   - 用户级线程由应用程序通过线程库实现。
   - 所有的**线程管理工作**都由**应用程序**负责（包括线程切换)
   - 用户级线程中，**线程切换**可以在**用户态**下即可完成，无需操作系统干预。
   - 在用户看来，是有多个线程。但是在操作系统内核看来，并意识不到线程的存在。（用户级线程对用户不透明，对操作系统透明)
   - 可以这样理解，“用户级线程”就是**“从用户视角看能看到的线程”**
-  内核级线程 
   - ![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230208144833304.png#id=e70BV&originHeight=616&originWidth=724&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
   - **内核级线程的管理**工作由**操作系统内核**完成。
   - 线程调度、切换等工作都由内核负责，因此**内核级线程的切换**必然需要在**核心态**下才能完成。
可以这样理解，“内核级线程”就是**“从操作系统内核视角看能看到的线程”**
-  在同时支持用户级线程和内核级线程的系统中，可采用二者组合的方式:将n个用户级线程映射到m个内核级线程上（ n >= m) 
   - ![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230208145009254.png#id=gQOpV&originHeight=610&originWidth=700&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
-  **内核级线程才是处理机分配的单位** 
-  例如:上面这个模型中，该进程由**两个内核级线程，三个用户级线程**，在用户看来，这个进程中有三个线程。但即使该进程在一个4核处理机的计算机上运行，也最多只能被分配到两个核，**最多只能有两个用户线程并行执行。** 
### 多线程模型

- 多对一模型： 
   - 多个用户及线程映射到一个内核级线程。每个用户进程只对应一个内核级线程。
   - 优点:用户级线程的**切换**在**用户空间即可完成**，不需要切换到核心态，线程管理的系统开销小，效率高
   - 缺点:当一个用户级**线程被阻塞**后，整个**进程都会被阻塞**，**并发度不高**。多个线程**不可在多核处理机上并行运行**
   - ![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230208145340465.png#id=Xu8YX&originHeight=616&originWidth=656&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
- 一对一模型： 
   - 一个用户及线程映射到一个内核级线程。每个用户进程有与用户级线程同数量的内核级线程。
   - 优点:当一个线程被**阻塞后**，别的线程**还可以继续执行**，**并发能力强**。**多线程可在多核处理机上并行执行。**
   - 缺点:**一个用户进程会占用多个内核级线程,**线程**切换**由操作**系统内核**完成，**需要切换到核心态**，因此线程管理的成本高，开销大。
   - ![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230208145555074.png#id=nyTA3&originHeight=623&originWidth=712&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
- 多对多模型： 
   - n用户及线程映射到m个内核级线程(n >= m）。每个用户进程对应m个内核级线程。
   - 克服了多对一模型并发度不高的缺点，又克服了一对一模型中一个用户进程占用太多内核级线程，开销太大的缺点。
   - ![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230208145009254.png#id=u8PG6&originHeight=610&originWidth=700&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
### 总结
![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230208145838396.png#id=STCXG&originHeight=785&originWidth=1221&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
## 2.2.1 处理机调度的概念、层次
### 调度的基本概念

-  当有一堆任务要处理，但由于资源有限，这些事情没法同时处理。这就需要确定**某种规则**来决定处理这些任务的**顺序**，这就是“调度”研究的问题。 
-  在多道程序系统中，进程的数量往往是多于处理机的个数的，这样不可能同时并行地处理各个进程。 
-  **处理机调度**，就是从**就绪队列**中按照**一定的算法**选择一个进程**并将处理机分配给它运行**，以实现进程的并发执行。 
### 高级调度

- 由于内存空间有限，有时无法将用户提交的作业全部放入内存，因此就需要确定某种规则来决定将作业调入内存的顺序。
- **高级调度（作业调度)**。按一定的原则从外存上处于后备队列的作业中挑选一个(或多个）作业，给他们**分配内存等必要资源，并建立相应的进程（建立PCB)**，以使它（们）获得竞争处理机的权利。
- **高级调度**是**辅存（外存）与内存**之间的调度。每个作业**只调入一次，调出一次**。作业**调入**时会**建立相应的PCB**，作业调出时才撤销PCB。
- 高级调度主要是指调入的问题，因为只有调入的时机需要操作系统来确定，但调出的时机必然是作业运行结束才调出。
### 中级调度

- 引入了虚拟存储技术之后，可将暂时不能运行的进程调至外存等待。等它重新具备了运行条件且内存又稍有空闲时，再重新调入内存。
- 这么做的目的是为了**提高内存利用率和系统吞吐量。**
- 暂时调到外存等待的进程状态为**挂起状态**。值得注意的是，**PCB并不会一起调到外存，而是会常驻内存**。PCB中会记录进程数据在外存中的存放位置，进程状态等信息，操作系统通过内存中的PCB来保持对各个进程的监控、管理。被挂起的进程PCB会被放到的**挂起队列**中。
- **中级调度（内存调度）**，就是要**决定**将哪个处于挂起状态的进程重新调入内存。
- 一个进程可能会被**多次调出、调入内存**，因此中级调度发生的频率要比高级调度更高。
- 七状态模型： 
   - ![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230208193110282.png#id=iywnJ&originHeight=566&originWidth=1479&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
### 低级调度

- **低级调度（进程调度）**，其主要任务是按照某种方法和策略**从就绪队列中选取一个进程**，将**处理机分配给它。**
- 进程调度是操作系统中**最基本的一种调度**，在一般的操作系统中都必须配置进程调度。进程调度的**频率很高**，一般几十毫秒一次。

![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230208193311141.png#id=TC8Nk&originHeight=473&originWidth=1299&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
### 总结
![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230208193452008.png#id=hGd7I&originHeight=714&originWidth=1548&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
## 2.2.2 进程调度的时机、切换与过程、方式
### 进程调度的时机

- **需要进行**进程调度与切换的情况 
   - 当前运行的进程**主动放弃**处理机 
      - 进程正常终止
      - 运行过程中发生异常而终止
      - 进程主动请求阻塞（如等待I/O）
   - 当前运行的进程**被动放弃**处理机 
      - 分给进程的时间片用完
      - 有更紧急的事需要处理（如I/O中断）
      - 有更高优先级的进程进入就绪队列
- **不能进行**进程调度与切换的情况 
   - 在**处理中断的过程中**。中断处理过程发杂，与硬件密切相关，很难做到在中断处理中进行进程切换。
   - 进程在**操作系统内核程序临界区**中。
   - 在**原子操作过程中（原语）**。原子操作不可中断，要一气呵成（如之前讲过的修改PCB中进程状态标志，并把PCB放到相应队列)
- -真题易错 
   - ![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230208194649412.png#id=sGUzp&originHeight=728&originWidth=1472&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
### 进程调度的方式

- **非剥夺调度方式，又称非抢占方式**。即，**只允许**进程**主动放弃**处理机。在运行过程中即便有更紧迫的任务到达，当前进程依然会继续使用处理机，直到该进程终止或主动要求进入阻塞态。 
   - 实现简单，系统开销小，但是无法及时处理紧急任务，适用于**早期的批处理系统**
- **剥夺调度方式，又称抢占方式**。当一个进程正在处理机上执行时，如果有一个更重要或更紧迫的进程需要使用处理机，则立即暂停正在执行的进程，**将处理机分配给更重要紧迫的那个进程**。 
   - 可以优先处理更紧急的进程，也可实现让各进程**按时间片轮流执行**的功能（通过时钟中断）。适合于**分时操作系统、实时操作系统**
### 进程的切换与过程

- “狭义的进程调度”与“进程切换”的区别: 
   - **狭义的进程调度**指的是从就绪队列中**选中一个要运行的进程**。(这个进程可以是刚刚被暂停执行的进程，也可能是**另一个进程**，后一种情况就需要进程切换)
   - **进程切换**是指一个进程让出处理机，由另一个进程占用处理机的过程。
   - **广义的进程调度**包含了选择一个进程和进程切换两个步骤。
- **进程切换**的过程主要完成了: 
   - **对原来**运行进程各种数据的**保存**
   - **对新的**进程各种数据的**恢复**
(如:**程序计数器、程序状态字、各种数据寄存器**等处理机现场信息，这些信息一般保存在**进程控制块**)
   - 注意:**进程切换是有代价的**，因此如果**过于频繁**的进行进程调度、切换，必然会使整个系统的**效率降低**，使系统大部分时间都花在了讲程切换上，而真正用于执行讲程的时间减少。
### 总结
![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230208195516932.png#id=ItCA2&originHeight=808&originWidth=1332&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
## 2.2.3 调度算法的评价指标
### CPU利用率

- **CPU利用率**:指CPU“忙碌”的时间占总时间的比例。
- 利用率 = 忙碌的时间 / 总时间
- 例：![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230208195823107.png#id=WP7cB&originHeight=311&originWidth=978&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
### 系统吞吐量

- **系统吞吐量**：单位时间内完成作业的数量
- 系统吞吐量 = 总共完成多少道作业 / 总共花了多少时间
- 例：![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230208195945476.png#id=rh4fO&originHeight=130&originWidth=955&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
### 周转时间

- **周转时间**：是指从作业**被提交**给系统开始，**到作业完成**为止的这段时间间隔
- 它包括四个部分:（后三项在一个作业的整个处理过程中，可能发生多次。） 
   - 作业在**外存后备队列**上等待作业调度**（高级调度）**的时间
   - 进程在**就绪队列**上等待进程调度**（低级调度）的时间**
   - 进程在CPU上**执行的时间**
   - 进程**等待I/o操作完成**的时间。
- (作业）周转时间 = 作业完成时间 - 作业提交时间
- 平均周转时间 = 各作业周转时间之和 / 作业数

![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230208200401173.png#id=RWBsU&originHeight=122&originWidth=1023&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
### 等待时间

-  **等待时间**，指进程/作业**处于等待处理机状态时间之和**，等待时间越长，用户满意度越低。 
-  对于**进程**来说，等待时间就是**指进程建立后等待被服务的时间之和**，在**等待I/o完成**的期间其实进程也是在被服务的，所以**不计**入等待时间。 
-  对于**作业**来说，不仅要考虑建立进程后的等待时间，还要**加上作业在外存后备队列中等待的时间**。 
### 响应时间

- **响应时间**，指从用户**提交请求**到**首次产生响应**所用的时间。
### 总结
![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230208200751565.png#id=SLoKY&originHeight=741&originWidth=768&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
## 2.2.4 调度算法
### 先来先服务（FCFS,First Come First Serve）
![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230208202337462.png#id=jZavh&originHeight=682&originWidth=1384&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
### 短作业优先（SJF,Shortest Job First）
![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230208203559644.png#id=gSQ2T&originHeight=717&originWidth=1367&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
### 高响应比优先（HRRN，Highest Response Ratio Next）
![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230208204227864.png#id=Oj93n&originHeight=661&originWidth=1469&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
### 总结

- 注:这几种算法主要关心对用户的公平性、平均周转时间、平均等待时间等评价系统整体性能的指标，但是不关心“响应时间”，也并不区分任务的紧急程度，因此对于用户来说，交互性很糟糕。因此这三种算法一般适合用于**早期的批处理系统**
- 当然，FCFS算法也常结合其他的算法使用，在现在也扮演着很重要的角色。而适合用于交互式系统的调度算法将在下个小节介绍.
### 时间片轮转（RR,Round-Robin）
![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230209091504132.png#id=PAhlL&originHeight=706&originWidth=1375&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)

- 如果**时间片太大**，使得每个进程都可以在一个时间片内就完成，则时间片轮转调度算法**退化为先来先服务**调度算法，并且会**增大进程响应时间**。因此时间片不能太大。
- 另一方面，进程调度、切换是有时间代价的（保存、恢复运行环境)，因此如果**时间片太小**，会导致**进程切换过于频繁**，系统会花大量的时间来处理进程切换，从而导致实际用于进程执行的时间比例减少。可见时间片也不能太小。
### 优先级调度算法
![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230209132115040.png#id=pI8Qq&originHeight=700&originWidth=1343&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)

- 就绪队列未必只有一个，可以按照不同优先级来组织。另外，也可以把优先级高的进程排在更靠近队头的位置
- 根据优先级是否可以动态改变，可将优先级分为静态优先级和动态优先级两种。 
   - **静态优先级**:创建进程时确定，之后一直不变。
   - **动态优先级**:创建进程时有一个初始值，之后会根据情况动态地调整优先级
- 通常: 
   - **系统进程**优先级**高于用户进程**前台进程优先级高于后台进程
   - **前台进程**优先级**高于后台进程**
   - 操作系统更**偏好l/o型进程（或称l/o繁忙型进程)** 
      - 与I/o型进程相对的是**计算型进程（或称CPU繁忙型进程)**
### 多级反馈队列
![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230209133113000.png#id=zXceF&originHeight=759&originWidth=1499&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
### 总结
![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230209133215492.png#id=q8Irp&originHeight=468&originWidth=1496&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)

- 注:比起早期的批处理操作系统来说，由于计算机造价大幅降低，因此之后出现的交互式操作系统〈包括分时操作系统、实时操作系统等）更注重系统的响应时间、公平性、平衡性等指标。而这几种算法恰好也能较好地满足交互式系统的需求。因此这三种算法适合用于交互式系统。(比如UNIX使用的就是多级反馈队列调度算法)
## 2.3.1 进程同步、进程互斥
### 进程同步

- ![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230209153235081.png#id=AT7U0&originHeight=162&originWidth=1351&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
- 读进程和写进程并发地运行，由于**并发必然导致异步性**，因此“写数据”和“读数据”两个操作执行的先后顺序是不确定的。而实际应用中，又必须按照**“写数据→读数据”**的顺序来执行的。**如何解决这种异步问题，就是“进程同步”所讨论的内容。**
- **同步**亦称**直接制约关系**，它是指为完成某种任务而建立的两个或多个进程，这些进程因为需要在某些位置上**协调它们的工作次序**而产生的制约关系。进程间的直接制约关系就是源于它们之间的相互合作。
### 进程互斥

- 我们把**一个时间段内只允许一个进程使用**的资源称为**临界资源**。许多物理设备（比如摄像头、打印机）都属于临界资源。此外还有许多变量、数据、内存缓冲区等都属于临界资源。
- 对临界资源的访问，必须**互斥**地进行。互斥，亦称**间接制约关系**。**进程互斥**指当一个进程访问某临界资源时，另一个想要访问该临界资源的进程必须等待。当前访问临界资源的进程访问结束，释放该资源之后，另一个进程才能去访问临界资源。
```c
do {
    entry section;//进入区（负责检查是否可进入临界区，若能进入，则应该设置正在访问临界资源的标志，阻止其他进程进入）
    
    critical section;//临界区（访问临界资源的代码）
    
    exit section;//退出区（负责接触正在访问临界资源的标志）
    
    remainder section;//剩余区（做其他处理）
}
```

-  **临界区**是进程中**访问临界资源**的代码段。 
-  **进入区和退出区**是**负责实现互斥**的代码段。 
-  临界区也可称为“临界段”。 
-  为了实现对临界资源的互斥访问，同时保证系统整体性能，需要遵循以下原则: 
   - 1．**空闲让进**。临界区空闲时，可以允许一个请求进入临界区的进程立即进入临界区;
   - 2．**忙则等待**。当已有进程进入临界区时，其他试图进入临界区的进程必须等待;
   - 3．**有限等待**。对请求访问的进程，应保证能在有限时间内进入临界区（保证不会饥饿）;
   - 4． **让权等待**。当进程不能进入临界区时，应立即释放处理机，防止进程忙等待。
## 2.3.2 进程互斥的软件实现方法
### 单标志法

- 算法思想:两个进程在**访问完临界区后**会把使用临界区的权限转交给另一个进程。也就是说**每个进程进入临界区的权限只能被另一个进程赋予**

![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230209160730627.png#id=qwTi8&originHeight=352&originWidth=1379&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)

- turn表示当前允许进入临界区的进程号，而只有当前允许进入临界区的进程在访问了临界区之后，会修改turn的值。也就是说，对于临界区的访问，一定是按PO→P1→PO→P1→.....这样轮流访戊这种必须“轮流访问”带来的问题是，**如果此时允许进入临界区的进程是Po，而PO一直不访问临区，那么虽然此时临界区空闲，但是并不允许P1访问。**
- 因此，单标志法存在的主要问题是:**违背“空闲让进”原则。**
### 双标志先检查法

- 算法思想:设置一个布尔型数组flag[]，数组中各个元素用来**标记各进程想进入临界区的意愿**，比如“flag[0] =ture”意味着0号进程PO现在想要进入临界区。每个进程在进入临界区之前先检查当前有没有别的进程想进入临界区，如果没有，则把自身对应的标志 flag[i]设为true，之后开始访问临界区。
- ![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230209161431051.png#id=OJ4N9&originHeight=395&originWidth=1483&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
- 若按照①⑤②⑥3⑦....的顺序执行，PO和P1将会同时访问临界区。
- 因此，双标志先检查法的主要问题是:**违反“忙则等待”原则。**
原因在于，**进入区**的“检查”和“上锁”**两个处理不是一气呵成的**。“检查”后，“上锁”前可能发生进程切换。
### 双标志后检查法
![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230209161757681.png#id=DMpm8&originHeight=391&originWidth=1468&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)

- 若按照①⑤②⑥....的顺序执行，PO和P1将都无法进入临界区
- 因此，双标志后检查法虽**然解决了“忙则等待”**的问题，但是又**违背了“空闲让进”和“有限等待”原则**，会因各进程都长期无法访问临界资源而**产生“饥饿”现象。**
- 两个进程都争着想进入临界区，但是谁也不让谁，最后谁都无法进入临界区
### Peterson算法
![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230209162248897.png#id=nGUwm&originHeight=628&originWidth=1403&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)

- 算法思想:双标志后检查法中，两个进程都争着想进入临界区，但是谁也不让谁，最后谁都无法进入临界区。Gary L.Peterson想到了一种方法，如果双方都争着想进入临界区，那可以让进程尝试“孔融让梨”，主动让对方先使用临界区。
- Peterson算法用软件方法**解决了进程互斥问题，遵循了空闲让进、忙则等待、有限等待三个原则**，但是依然**未遵循让权等待**的原则。
### 总结
![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230209162635672.png#id=IvduY&originHeight=666&originWidth=1432&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
## 2.3.3 进程互斥的硬件实现方法
### 中断屏蔽方法

-  利用**“开/关中断指令”**实现（与原语的实现思想相同，即在某进程开始访问临界区到结束访问为止都不允许被中断，也就不能发生进程切换，因此也不可能发生两个同时访问临界区的情况) 
-  优点:**简单、高效** 
-  缺点: 
   - **不适用于多处理机**;
   - 只适用于操作系统**内核进程**，不适用于用户进程（因为开/关中断指令只能运行在内核态，这组指令如果能让用户随意使用会很危险)
### TestAndSet指令

- 简称TS指令，也有地方称为TestAndSetLock指令，或TSL指令
- TSL指令是用硬件实现的，执行的过程不允许被中断，只能一气呵成。

C语言描述的逻辑：
```c
//lock表示当前临界区是否被加锁
bool TestAndSet(bool *lock)
{
    bool old;
    old = *lock;//old用来存放lock原来的值
    *lock = true;//无论之前是否加锁，都将lock设为true
    return old;//返回lock原来的值
}

//以下是使用TSL指令实现互斥的算法逻辑
while (TestAndSet(&lock));
临界区代码段
lock = false; //解锁
剩余区代码段
```

-  若刚开始lock是false，则TSL返回的old值为false，while循环条件不满足，直接跳过循环，进入临界区。若刚开始lock是true，则执行TLS后old返回的值为true，while循环条件满足，会一直循环，直到当前访问临界区的进程在退出区进行“解锁”。 
-  相比软件实现方法，TSL指令把“上锁”和“检查”操作用硬件的方式变成了一气呵成的原子操作。 
-  优点:实现**简单**，无需像软件实现方法那样严格检查是否会有逻辑漏洞;**适用于多处理机环境** 
-  缺点:**不满足“让权等待”原则**，暂时无法进入临界区的进程会占用CPu并循环执行TSL指令，从而导致“忙等”。 
### Swap指令

- 有的地方也叫Exchange指令，或简称XCHG指令。
- Swap指令是用硬件实现的，执行的过程不允许被中断，只能一气呵成。

C语言描述的逻辑：
```c
Swap(bool *a,bool *b)
{
    bool temp;
    temp *a;
    *a = *b;
    *b = temp;
}

bool old = true;
while(old == true)
    Swap(&lock,&old);
临界区代码段
lock = false;
剩余区代码段
```

- 逻辑上来看Swap和TSL并无太大区别，都是先记录下此时临界区是否已经被上锁(记录在 old变量上），再将上锁标记lock设置为true，最后检查old，如果old为 false则说明之前没有别的进程对临界区上锁，则可跳出循环，进入临界区。
- 优点:实现**简单**，无需像软件实现方法那样严格检查是否会有逻辑漏洞;适用于多处理机环境
- 缺点:**不满足“让权等待”原则**，暂时无法进入临界区的进程会占用CPU并循环执行TSL指令，从而导致“忙等”。
### 总结
![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230212113403113.png#id=WV1yU&originHeight=686&originWidth=1494&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
## 2.3.4 信号量机制
### 信号量机制

- 用户进程可以通过使用操作系统提供的**一对原语**来对**信号量**进行操作，从而很方便的实现了进程互斥、进程同步。
- **信号量**其实就是一个变量**（可以是一个整数，也可以是更复杂的记录型变量)**，可以用一个信号量**来表示系统中某种资源的数量**，比 
   - 如:系统中只有一台打印机，就可以设置一个初值为1的信号量。
- **原语**是一种特殊的程序段，其**执行只能一气呵成，不可被中断。**原语是由**关中断/开中断指令**实现的。软件解决方案的主要问题是由“进入区的各种操作无法一气呵成”，因此如果能把进入区、退出区的操作都用“原语”实现，使这些操作能“一气呵成”就能避免问题。
- **一对原语**: **wait(S)原语**和**signal(S)原语**，可以把原语理解为我们自己写的函数，函数名分别为wait和signal，括号里的**信号量s**其实就是函数调用时传入的一个参数。
- wait、signal原语常**简称为P、v操作**（来自荷兰语proberen和 verhogen)。因此，做题的时候常把wait(S)、signal(S)两个操作分别写为**P(S)、v(S)**
### 整型信号量

- 用一个**整数型的变量**作为信号量，**用来表示系统中某种资源的数量.** 
   - 与普通整数变量的区别:对**信号量的操作**只有三种,即**初始化、P操作、V操作**
```c
int s = 1;//初始化整型信号量s，表示当前系统中可用的打印机资源数

void wait (int s)// wait原语，相当于“进入区”
{
    while (s <= 0);//如果资源数不够，就一直循环等待
	s=S-1;//如果资源数够，则占用一个资源
}


void signal (int S) //signal原语，相当于“退出区”
{
    S=S+1;//使用完资源后，在退出区释放资源
}
```
![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230212144603466.png#id=Hwei8&originHeight=234&originWidth=1289&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)

- “检查”和“上锁”一气呵成,避免了并发、异步导致的问题
- 存在的问题: 不满足“让权等待原则，会发生“忙等”
### 记录型信号量

- 整型信号量的缺陷是存在“忙等”问题，因此人们又提出了“记录型信号量”，即**用记录型数据结构表示的信号量。**
```c
/*记录型信号量的定义*/
typedef struct 
{
    int value;//剩余资源数
	Struct process *L;//等待队列
} semaphore;

/*某进程需要使用资源时，通过wait原语申请*/
void wait (semaphore s) 
{
	s.value--;
	if (S.value < 0)
    {
        block (S.L);
    }
}

/*进程使用完资源后，通过signal原语释放*/
void signal (semaphore s) 
{
	s.value++;
	if (s.value <= 0) 
    {
        wakeup(S.L);
	}
}
```

- 在考研题目中wait(S)、signal(S)也可以记为P(S)、v(S)，这对原语可用于**实现系统资源的“申请”和“释放”。**
- **S.value的初值**表示系统中**某种资源的数目。**
- 对信号量s的**一次Р操作**意味着进程**请求一个单位的该类资源**，因此需要执行S.value--，表示资源数减1，当s.value <0时表示该类资源已分配完毕，因此进程应**调用block原语进行自我阻塞**（当前运行的进程从运行态→阻塞态），主动放弃处理机，并插入该类资源的等待队列s.L中。可见，**该机制遵循了“让权等待”原则，不会出现“忙等”现象。**
- 对信号量S的**一次V操作**意味着进程**释放一个单位的该类资源**，因此需要执行S.value++，表示资源数加1，若加1后仍是S.value <=o，表示依然有进程在等待该类资源，因此应**调用wakeup原语唤醒等待队列中的第一个进程**（被唤醒进程从**阻塞态→就绪态**）。
### 总结

-  ![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230212150300629.png#id=pQxcj&originHeight=619&originWidth=1526&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
-  注:若考试中出现P(S)、V(S)的操作，除非特别说明，否则**默认S为记录型信号量。** 
## 2.3.5 用信号量实现进程互斥、同步、前驱关系
### 信号量机制实现进程互斥

-  分析并发进程的关键活动，划定临界区（如:对临界资源打印机的访问就应放在临界区) 
-  设置**互斥信号量mutex**，**初值为1** 
-  在临界区之前执行P(mutex) 
-  在临界区之后执行V(mutex) 
-  注意:对不同的临界资源需要设置不同的互斥信号量。 

![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230212150957851.png#id=f9WOl&originHeight=319&originWidth=825&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)

- P、V操作必须成对出现。
- 缺少P(mutex)就不能保证临界资源的互斥访问。缺少V(mutex)会导致资源永不被释放，等待进程永不被唤醒。
### 信号量机制实现进程同步

-  进程同步:要让各并发进程按要求**有序地推进**。 
-  用信号量实现进程同步: 
   - 1．分析什么地方需要实现“同步关系”，即必须保证“一前一后”执行的两个操作（或两句代码)
   - 2．**设置同步信号量**s,**初始为0**
   - 3．**在“前操作”之后执行v(S)**
   - 4．**在“后操作”之前执行P(S)**
- ![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230212151624100.png#id=RvbZs&originHeight=403&originWidth=757&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
-  若先执行到v(S)操作，则S++后S=1。之后当执行到P(S)操作时，由于S=1，表示有可用资源，会执行S--，s的值变回0，P2进程不会执行block原语，而是继续往下执行代码4。 
-  若先执行到P(S)操作，由于S=0，S--后S=-1，表示此时没有可用资源，因此P操作中会执行block原语，主动请求阻塞。之后当执行完代码2，继而执行v(S)操作，S++，使s变回0，由于此时有进程在该信号量对应的阻塞队列中，因此会在v操作中执行wakeup原语，唤醒P2进程。这样P2就可以继续执行代码4了 
### 信号量机制实现前驱关系
![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230212152339206.png#id=GptUt&originHeight=722&originWidth=1498&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
### 总结
![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230212152519788.png#id=aQQpc&originHeight=739&originWidth=1547&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
## 2.3.6 生产者-消费者问题
### 用P、V操作解决问题

- 系统中有一组生产者进程和一组消费者进程，生产者进程每次生产一个产品放入缓冲区，消费者进程每次从缓冲区中取出一个产品并使用。(注:这里的“产品”理解为某种数据) 
   - 生产者、消费者共享一个**初始为空、大小为n的缓冲区。**
   - 只有**缓冲区没满**时，生产者才能把产品放入缓冲区，否则必须等待。**（同步关系）**
   - 只有**缓冲区不空**时，消费者才能从中取出产品，否则必须等待。**（同步关系）**
   - 缓冲区是临界资源，各进程必须**互斥地访问**。**（互斥关系）**

![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230212153831148.png#id=tTFG9&originHeight=457&originWidth=1273&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230212154236684.png#id=zcAIr&originHeight=556&originWidth=1621&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
### 能否改变相邻的P、V操作的顺序？
![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230212154356688.png#id=gOXd2&originHeight=409&originWidth=1350&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)

- 若此时缓冲区内已经放满产品，则empty=o，full=n。
- 则生产者进程执行①使mutex变为0，再执行②，由于已没有空闲缓冲区，因此生产者被阻塞。由于生产者阻塞，因此切换回消费者进程。消费者进程执行③，由于mutex为o，即生产者还没释放对临界资源的“锁”，因此消费者也被阻塞。
- 这就造成了生产者等待消费者释放空闲缓冲区，而消费者又等待生产者释放临界区的情况，生产者和消费者循环等待被对方唤醒，出现“死锁”。
- 同样的，若缓冲区中没有产品，即full=0，empty=n。按③④①的顺序执行就会发生死锁。
- 因此，**实现互斥的P操作一定要在实现同步的P操作之后。**
- V操作不会导致进程阻塞，因此**两个v操作顺序可以交换。**
### 总结

- PV操作题目的解题思路: 
   - 1．关系分析。找出题目中描述的各个进程，分析它们之间的同步、互斥关系。
   - 2．整理思路。根据各进程的操作流程确定P、V操作的大致顺序。
   - 3．设置信号量。设置需要的信号量，并根据题目条件确定信号量初值。(互斥信号量初值一般为1，同步信号量的初始值要看对应资源的初始值是多少)
## 2.3.7 多生产者-多消费者问题
### 问题描述

- 桌子上有一只盘子，每次只能向其中放入一个水果。
- 爸爸专向盘子中放苹果，妈妈专向盘子中放橘子
- 儿子专等着吃盘子中的橘子，女儿专等着吃盘子中的苹果。
- 只有盘子空时，爸爸或妈妈才可向盘子中放一个水果。
- 仅当盘子中有自己需要的水果时，儿子或女儿可以从盘子中取出水果。
- 用PV操作实现上述过程。

![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230212160921735.png#id=TACtC&originHeight=541&originWidth=1520&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)

- 互斥关系: 
   - 对缓冲区（盘子)的访问要互斥地进行
- 同步关系（一前一后）: 
   - 1.父亲将苹果放入盘子后，女儿才能取苹果
   - 2.母亲将橘子放入盘子后，儿子才能取橘子
   - 3.只有盘子为空时，父亲或母亲才能放入水果

![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230212161053068.png#id=W9BAf&originHeight=794&originWidth=1558&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
## 2.3.10 学家进餐问题
### 问题描述

- 一张圆桌上坐着5名哲学家，每两个哲学家之间的桌上摆一根筷子，桌子的中间是一碗米饭。哲学家们倾注毕生的精力用于思考和进餐，哲学家在思考时，并不影响他人。只有当哲学家饥饿时，才试图拿起左、右两根筷子（一根一根地拿起)。如果筷子已在他人手上，则需等待。饥饿的哲学家只有同时拿起两根筷子才可以开始进餐，当进餐完毕后，放下筷子继续思考。

![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230212200232000.png#id=p5TFJ&originHeight=596&originWidth=690&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
### 如何防止死锁

- 1、可以对哲学家进程施加一些限制条件，比如最多允许四个哲学家同时进餐。这样可以保证至少有一个哲学家是可以拿到左右两只筷子的
```c
semaphore count = 4;//最大同时吃饭人数
semaphore chopstick[5] = {1,1,1,1,1};

Pi()//i号哲学家
{
    while(1)
    {
        P(count);//占据一个吃饭人数
        P(chopstick[i]);//拿左手筷子
        P(chopstick[(i+1)%5]);//拿右手筷子
        吃饭
        V(chopstick[i]);//放左手筷子
        V(chopstick[(i+1)%5]);//放右手筷子
        V(count);//释放一个吃饭人数
    }
}
```

- 2、要求奇数号哲学家先拿左边的筷子，然后再拿右边的筷子，而偶数号哲学家刚好相反。用这种方法可以保证如果相邻的两个奇偶号哲学家都想吃饭，那么只会有其中一个可以拿起第一只筷子，另一个会直接阻塞。这就避免了占有一支后再等待另一只的情况。
```c
semaphore chopstick[5] = {1,1,1,1,1};

Pi()
{
    while(1)
    {
        if(i%2 == 0)
        {
            P(chopstick[i]);//拿左手筷子
        	P(chopstick[(i+1)%5]);//拿右手筷子
            吃饭
            V(chopstick[i]);//放左手筷子
        	V(chopstick[(i+1)%5]);//放右手筷子
        }
        else if(i%2 == 1)
        {
        	P(chopstick[(i+1)%5]);//拿右手筷子
            P(chopstick[i]);//拿左手筷子
            吃饭
        	V(chopstick[(i+1)%5]);//放右手筷子
            V(chopstick[i]);//放左手筷子
        }
    }
}
```

- 3、各哲学家拿筷子这件事必须互斥的执行。这就保证了即使一个哲学家在拿筷子拿到一半时被阻塞，也不会有别的哲学家会继续尝试拿筷子。这样的话，当前正在吃饭的哲学家放下筷子后，被阻塞
的哲学家就可以获得等待的筷子了。
```c
semaphore chopstick[5] = {1,1,1,1,1};
semaphore mutex = 1;

Pi()//i号哲学家
{
    while(1)
    {
    	P(mutex);
        P(chopstick[i]);//拿左手筷子
        P(chopstick[(i+1)%5]);//拿右手筷子
        V(mutex);
        吃饭
        V(chopstick[i]);//放左手筷子
        V(chopstick[(i+1)%5]);//放右手筷子
    }
}
```
### 总结

- 哲学家进餐问题的关键在于解决进程死锁。
- 这些进程之间只存在互斥关系，但是与之前接触到的互斥关系不同的是，每个进程都需要同时持有两个临界资源，因此就有“死锁”问题的隐患。
- 如果在考试中遇到了一个进程需要同时持有多个临界资源的情况，应该参考哲学家问题的思想，分析题中给出的进程之间是否会发生循环等待，是否会发生死锁。
- 可以参考哲学家就餐问题解决死锁的三种思路。
## 2.3.10 管程
### 管程的定义和基本特征

-  管程是一种特殊的软件模块，有这些部分组成:（管程可以类比与面向对象的类） 
   - 1．局部于管程的**共享数据结构**说明;
   - 2．对该数据结构进行操作的**一组过程**;（过程相当于函数）
   - 3．对局部于管程的共享数据设置初始值的语句;
   - 4．管程有一个名字。
-  管程的基本特征: 
   - 1．局部于管程的数据只能被局部于管程的过程所访问;
   - 2．一个进程只有通过调用管程内的过程才能进入管程访问共享数据;
   - **3．每次仅允许一个进程在管程内执行某个内部过程。**
### 用管程处理生产者消费者问题
![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230212204355715.png#id=x72RD&originHeight=697&originWidth=1369&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)

- 引入管程的目的无非就是要更方便地实现进程互斥和同步。 
   - 1．需要在管程中定义共享数据（如生产者消费者问题的缓冲区)
   - 2．需要在管程中定义用于访问这些共享数据的“入口”―—其实就是一些函数（如生产者消费者问题中，可以定义一个函数用于将产品放入缓冲区，再定义一个函数用于从缓冲区取出产品)
   - 3．**只有通过这些特定的“入口”才能访问共享数据**
   - 4．管程中有很多“入口”，但是**每次只能开放其中一个“入口”**，并且**只能让一个进程或线程进入**(如生产者消费者问题中，各进程需要互斥地访问共享缓冲区。管程的这种特性即可保证一个时间段内最多只会有一个进程在访问缓冲区。**注意:这种互斥特性是由编译器负责实现的，程序员不用关心)**
   - 5．可在管程中设置**条件变量**及**等待/唤醒操作**以解决同步问题。可以让一个进程或线程在条件变量上等待（**此时，该进程应先释放管程的使用权，也就是让出“入口”)**;可以通过唤醒操作将等待在条件变量上的进程或线程唤醒。
   - 程序员可以用某种特殊的语法定义一个管程（比如: monitor ProducerConsumer .....end monitor;) ,之后其他程序员就可以使用这个管程提供的特定“入口”很方便地使用实现进程同步/互斥了。
### 总结
![](https://picgo-huangzhibin.oss-cn-hangzhou.aliyuncs.com/image/image-20230212205002019.png#id=ZIvh3&originHeight=645&originWidth=1463&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title=)
## 2.4.1 死锁的概念
### 什么是死锁

- 每个人都占有一个资源，同时又在等待另一个人手里的资源。发生“死锁”
- 在并发环境下，各进程因竞争资源而造成的一种**互相等待对方手里的资源，导致各进程都阻塞，都无法向前推进的现象，**就是“死锁”。发生死锁后若无外力干涉，这些进程都将无法向前推进。
### 死锁、饥饿、死循环的区别

- 死锁:各进程互相等待对方手里的资源，导致各进程都阻塞，无法向前推进的现象。
- 饥饿:由于长期得不到想要的资源，某进程无法向前推进的现象。比如:在短进程优先（SPF）算法中，若有源源不断的短进程到来，则长进程将一直得不到处理机，从而发生长进程“饥饿”。
- 死循环:某进程执行过程中一直跳不出某个循环的现象。有时是因为程序逻辑bug 导致的，有时是程序员故意设计的。

![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391014248-e14393cb-3c01-48fb-9c6b-640f713adf6b.png#averageHue=%23b4c4d9&clientId=u11b08f95-75c2-4&from=paste&id=u5f1a61c0&originHeight=451&originWidth=1399&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=u99f783f5-aae7-49d6-bd28-7c55162d991&title=)
### 死锁产生的必要条件

- 产生死锁必须同时满足一下四个条件，只要其中任一条件不成立，死锁就不会发生。
- **互斥条件**:只有对必须互斥使用的资源的争抢才会导致死锁（如哲学家的筷子、打印机设备）。像内存、扬声器这样可以同时让多个进程使用的资源是不会导致死锁的（因为进程不用阻塞等待这种资源）。
- **不剥夺条件:**进程所获得的资源在未使用完之前，不能由其他进程强行夺走，只能主动释放。
- **请求和保持条件**:进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源又被其他进程占有，此时请求进程被阻塞，但又对自己己有的资源保持不放。
- **循环等待条件**:存在一种进程资源的循环等待链，链中的每一个进程已获得的资源同时被下一个进程所请求。
   - **注意!发生死锁时一定有循环等待，但是发生循环等待时未必死锁**（循环等待是死锁的必要不充分条件)
   - 如果同类资源数大于1，则即使有循环等待，也未必发生死锁。但如果系统中每类资源都只有一个，那循环等待就是死锁的充分必要条件了。
### 什么时候会发生死锁

- 1．**对系统资源的竞争**。各进程对不可剥夺的资源（如打印机）的竞争可能引起死锁，对可剥夺的资源(CPU)的竞争是不会引起死锁的。
- 2．**进程推进顺序非法**。请求和释放资源的顺序不当，也同样会导致死锁。例如，并发执行的进程P1、P2分别申请并占有了资源R1、R2，之后进程P1又紧接着申请资源R2，而进程P2又申请资源R1，两者会因为申请的资源被对方占有而阻塞，从而发生死锁。
- 3．**信号量的使用不当**也会造成死锁。如生产者-消费者问题中，如果实现互斥的P操作在实现同步的P操作之前，就有可能导致死锁。(可以把互斥信号量、同步信号量也看做是一种抽象的系统资源)
- 总之，**对不可剥夺资源的不合理分配**，可能导致死锁。
### 死锁的处理策略

- 1．预防死锁。破坏死锁产生的四个必要条件中的一个或几个。
- 2．避免死锁。用某种方法防止系统进入不安全状态，从而避免死锁（银行家算法)
- 3．死锁的检测和解除。允许死锁的发生，不过操作系统会负责检测出死锁的发生，然后采取某种措施解除死锁。
### 总结
![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391014268-98632028-b268-4071-8b68-aba4562097b5.png#averageHue=%23f0f1ee&clientId=u11b08f95-75c2-4&from=paste&id=uf943aa59&originHeight=743&originWidth=1307&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=ubb6fa311-abf5-46f6-a626-04eadff57d2&title=)
## 2.4.2 死锁的处理策略——预防死锁
### 破坏互斥条件

- **互斥条件**:只有对必须互斥使用的资源的争抢才会导致死锁。
- 如果把只能互斥使用的资源改造为允许共享使用，则系统不会进入死锁状态。比如: SPOOLing技术。操作系统可以采用SPOOLing技术把独占设备在逻辑上改造成共享设备。比如用SPooLing技术将打印机改造为共享设备...

![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391014282-6e9768cf-4a70-4408-a9e2-21f3dedda061.png#averageHue=%2396b374&clientId=u11b08f95-75c2-4&from=paste&id=uc9a10a44&originHeight=404&originWidth=1432&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=ucd93c984-81d4-430d-8624-18210651379&title=)
### 破坏不剥夺条件

- **不剥夺条件**:进程所获得的资源在未使用完之前，不能由其他进程强行夺走,只能主动释放。
- 破坏不剥夺条件:
   - 方案一:当某个进程请求新的资源得不到满足时，它必须立即释放保持的所有资源，待以后需要时再重新申请。也就是说，即使某些资源尚未使用完，也需要主动释放，从而破坏了不可剥夺条件。
   - 方案二:当某个进程需要的资源被其他进程所占有的时候，可以由操作系统协助，将想要的资源强行剥夺。这种方式一般需要考虑各进程的优先级（比如:剥夺调度方式，就是将处理机资源强行剥夺给优先级更高的进程使用)
   - 该策略的**缺点**:
      - 1.实现起来比较复杂。
      - ⒉释放已获得的资源可能造成前一阶段工作的失效。因此这种方法一般只适用于易保存和恢复状态的资源，如CPU。
      - 3.反复地申请和释放资源会增加系统开销，降低系统吞吐量。
      - 4.若采用方案一，意味着只要暂时得不到某个资源，之前获得的那些资源就都需要放弃，以后再重新申请。如果一直发生这样的情况，就会导致进程饥饿。
### 破坏请求和保持条件

- **请求和保持条件**:进程**已经保持了至少一个资源**，但又提出了新的资源**请求，**而该资源又被其他进程占有，此时请求进程被阻塞，但又对自己已有的资源保持不放。
- 可以采用**静态分配方法**，即进程在运行前一次申请完它所需要的全部资源，在它的资源未满足前，不让它投入运行。一旦投入运行后，这些资源就一直归它所有，该进程就不会再请求别的任何资源了。
- 该策略实现起来简单，但也有明显的**缺点**:有些资源可能只需要用很短的时间，因此如果进程的整个运行期间都一直保持着所有资源，就会造成严重的资源浪费，**资源利用率极低**。另外，该策略也有**可能导致某些进程饥饿。**
### 破坏循环等待条件

- 循环等待条件:存在一种进程资源的循环等待链，链中的每一个进程已获得的资源同时被下一个进程所请求
- 可采用顺序资源分配法。首先给系统中的资源编号，规定每个进程必须按编号递增的顺序请求资源，同类资源（即编号相同的资源)一次申请完。
- 原理分析:一个进程只有已占有小编号的资源时，才有资格申请更大编号的资源。按此规则，已持有大编号资源的进程不可能逆向
- 回来申请小编号的资源，从而就不会产生循环等待的现象。假设系统中共有10个资源，编号为1,2,......10
- ![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391014283-642aaba3-7954-43c3-a875-d2be95f704eb.png#averageHue=%23e7e7e7&clientId=u11b08f95-75c2-4&from=paste&id=uf1919900&originHeight=361&originWidth=563&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=u28a24698-03a4-4ee2-80f4-b7706407d53&title=)
### 总结
![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391014277-a046a377-4865-4236-a380-02fafbcafcd5.png#averageHue=%23d7d5d1&clientId=u11b08f95-75c2-4&from=paste&id=u1cf954fb&originHeight=768&originWidth=1764&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=uda698695-a4c6-4e40-b64e-be5a6ab7ef7&title=)
## 2.4.3 死锁的处理策略——避免死锁
### 什么是安全序列

- 所谓**安全序列**，就是指如果系统按照这种序列分配资源，则每个进程都能顺利完成。只要能找出一个安全序列，系统就是**安全状态**。当然，**安全序列可能有多个**。
- 如果分配了资源之后，系统中找不出任何一个安全序列，系统就进入了**不安全状态**。这就意味着之后**可能**所有进程都无法顺利的执行下去。当然，如果有进程提前归还了一些资源，**那系统也有可能重新回到安全状态**，不过我们在分配资源之前总是要考虑到最坏的情况。
- 如果系统处于**安全状态，就一定不会发生死锁**。如果系统进入**不安全状态，就可能发生死锁**（处于不安全状态未必就是发生了死锁，但发生死锁时一定是在不安全状态)
- 因此可以在**资源分配之前预**先判断这次分配是否会**导致系统进入不安全状态**.以**此决定是否答应资源分配请求。这也是“银行家算法”的核心思想。**
### 银行家算法
![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391014932-cc0c15c8-85be-4a56-aca7-bea4ebb994b8.png#averageHue=%239cb57f&clientId=u11b08f95-75c2-4&from=paste&id=ue7c707c5&originHeight=842&originWidth=1469&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=uf76c4493-02de-41d8-b67d-a743ec87207&title=)
### 总结

- 数据结构:
   - 长度为m的一维数组Available表示还有多少可用资源
   - n_*m矩阵Max表示各进程对资源的最大需求数_
   - n*m矩阵Allocation表示已经给各进程分配了多少资源
   - Max - Allocation = Need矩阵表示各进程最多还需要多少资源
   - 用长度为m的一位数组Request表示进程此次申请的各种资源数
- 银行家算法步骤:
   - ①检查此次申请是否超过了之前声明的最大需求数
   - ②检查此时系统剩余的可用资源是否还能满足这次请求
   - ③试探着分配，更改各数据结构
   - ④用安全性算法检查此次分配是否会导致系统进入不安全状态
- 安全性算法步骤:
   - 检查当前的剩余可用资源是否能满足某个进程的最大需求，如果可以，就把该进程加入安全序列,并把该进程持有的资源全部回收。
   - 不断重复上述过程，看最终是否能让所有进程都加入安全序列。
- 系统处于不安全状态未必死锁，但死锁时一定处于不安全状态。系统处于安全状态一定不会死锁。
## 2.4.4 死锁的处理策略——检测和解除
### 死锁的检测

- 为了能对系统是否已发生了死锁进行检测，必须:
   - ①用**某种数据结构**来保存资源的请求和分配信息;
   - ②提供**一种算法**，利用上述信息来检测系统是否已进入死锁状态。

![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391015065-c8039559-d773-4180-b2ca-46badb3efa34.png#averageHue=%239cb27d&clientId=u11b08f95-75c2-4&from=paste&id=u8d02ff67&originHeight=623&originWidth=1464&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=uc5d1fbb7-21ee-444f-a20d-35df743d752&title=)
**直接看视频2.4.4 前十分钟**
### 死锁的解除

- 一旦检测出死锁的发生，就应该立即解除死锁。
- 补充:并不是系统中所有的进程都是死锁状态，用死锁检测算法**化简资源分配图后，还连着边的那些进程就是死锁进程**
- 解除死锁的主要方法有:
   - 1．**资源剥夺法**。挂起（暂时放到外存上）某些死锁进程，并抢占它的资源,将这些资源分配给其他的死锁进程。但是应防止被挂起的进程长时间得不到资源而饥饿。
   - 2．**撤销进程法**（或称**终止进程法**）。强制撤销部分、甚至全部死锁进程，并剥夺这些进程的资源。这种方式的优点是实现简单，但所付出的代价可能会很大。因为有些进程可能已经运行了很长时间，已经接近结束了，一旦被终止可谓功亏一篑，以后还得从头再来。
   - 3．**进程回退法**。让一个或多个死锁进程回退到足以避免死锁的地步。这就要求系统要记录进程的历史信息，设置还原点。
### 总结
![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391015107-081d9a3d-babc-48c8-bcba-eef8493375a7.png#averageHue=%23a5bb8d&clientId=u11b08f95-75c2-4&from=paste&id=ucdb5d83d&originHeight=684&originWidth=1547&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=ue9631d97-fb70-43bb-ac39-dc13e5356a8&title=)
## 3.1.1 内存的基础知识
### 什么是内存

- 内存是用于存放数据的硬件。程序执行前**需要先放到内存中才能被cPU处理。**
- 内存地址从0开始，每个地址对应一个存储单元
- 如果计算机**“按字节编址”**则**每个存储单元大小为1字节，即1B**，即**8个二进制位**
- 如果字长**为16位**的计算机**“按字编址”**，则每个**存储单元大小为1个字;**每个字的大小**为16个二进制位**
- 相对地址又称逻辑地址，绝对地址又称物理地址。
### 从写程序到程序运行
![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391015246-f9a430ee-d93b-4c57-ac91-7b250744d95e.png#averageHue=%23e3ad8d&clientId=u11b08f95-75c2-4&from=paste&id=uddf83305&originHeight=534&originWidth=1564&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=u5e965e14-6ca4-4528-931d-77ba49e086f&title=)

- 编译:由编译程序将用户源代码编译成若干个目标模块（编译就是把高级语言**翻译为机器语言**)
- 链接:由链接程序将编译后形成的一组目标模块，以及所需库函数链接在一起，形成一个完整的装入模块
- 装入（装载）:由装入程序将装入模块装入内存运行
- 装入的三种方式（用三种不同的方法完成逻辑地址到物理地址的转换）:
   - 1．绝对装入
   - 2．静态重定位
   - 3．动态重定位
### 绝对装入

- **绝对装入:**在编译时，如果知道程序将放到内存中的哪个位置，编译程序将产生绝对地址的目标代码。装入程序按照装入模块中的地址，将程序和数据装入内存。
- 绝对装入**只适用于单道程序环境。**
- 程序中使用的绝对地址，可在编译或汇编时给出，也可由程序员直接赋予。通常情况下都是编译或汇编时再转换为绝对地址。
### 静态重定位

- **静态重定位**:又称**可重定位装入**。编译、链接后的装入模块的地址都是从0开始的，指令中使用的地址、数据存放的地址都是相对于起始地址而言的逻辑地址。可根据内存的当前情况，将装入模块装入到内存的适当位置。装入时对地址进行**“重定位”**，将逻辑地址变换为物理地址（地址变换是在装入时一次完成的）。
- 静态重定位的特点是在一个作业装入内存时，**必须分配其要求的全部内存空间，**如果没有足够的内存，就不能装入该作业。作业一旦进入内存后，**在运行期间就不能再移动**，也不能再申请内存空间。
### 动态重定位

- **动态重定位**:又称**动态运行时装入**。编译、链接后的装入模块的地址都是从o开始的。装入程序把装入模块装入内存后，并不会立即把逻辑地址转换为物理地址，而是**把地址转换推迟到程序真正要执行时才进行**。因此装入内存后所有的地址依然是逻辑地址。这种方式需要一个**重定位寄存器**的支持。
### 链接的三种方式

- 链接的三种方式:
   - 1.静态链接:在程序运行之前,先将各目标模块及它们所需的库函数连接成一个完整的可执行文件（装入模块）﹐之后不再拆开。
   - 2.装入时动态链接:将各目标模块装入内存时，边装入边链接的链接方式。
   - 3.运行时动态链接:在程序执行中需要该目标模块时，才对它进行链接。其优点是便于修改和更新，便于实现对目标模块的共享。
### 总结
![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391015307-70efdf29-2516-4b66-886c-63ff8bb45fbf.png#averageHue=%23b3c2a2&clientId=u11b08f95-75c2-4&from=paste&id=ub5148449&originHeight=719&originWidth=1440&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=u97d47309-6896-4601-a90e-88f75aaf2ea&title=)
## 3.1.2 内存管理的概念

- 1.操作系统负责内存空间的分配与回收
- 2.操作系统需要提供某种技术从逻辑上对内存空间进行扩充
- 3.操作系统需要提供地址转换功能，负责程序的逻辑地址与物理地址的转换
- 4.操作系统需要提供内存保护功能。保证各进程在各自存储空间内运行，互不干扰
   - 方法一:在cpu中设置一对上、下限寄存器，存放进程的上、下限地址。进程的指令要访问某个地址时，CPU检查是否越界。
   - 方法二:采用重定位寄存器（又称基址寄存器）和界地址寄存器（又称限长寄存器）进行越界检查。重定位寄存器中存放的是进程的起始物理地址。界地址寄存器中存放的是进程的最大逻辑地址。
### 总结
![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391015881-0690a83e-fce5-4bfa-bebf-6224c5122717.png#averageHue=%23d8dbcf&clientId=u11b08f95-75c2-4&from=paste&id=u4ecefc75&originHeight=618&originWidth=1477&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=u8989623b-4738-4757-96c5-5f98ecbf321&title=)
## 3.1.3 覆盖与交换
### 覆盖技术

- 覆盖技术的思想:**将程序分为多个段（多个模块**）。常用的段常驻内存，不常用的段在需要时调入内存。
- 内存中分为**一个“固定区**”和**若干个“覆盖区”**。
- 需要常驻内存的段放在**“固定区”**中，**调入后就不再调出**（除非运行结束)
- 不常用的段放在**“覆盖区”**，**需要用到时调入内存，用不到时调出内存**
- **必须由程序员声明覆盖结构**，操作系统完成自动覆盖。
- 缺点:**对用户不透明**,增加了用户编程负担。覆盖技术只用于早期的操作系统中，现在已成为历史。
### 交换技术

- 交换（对换）技术的设计思想:内存空间紧张时，系统将内存中某些进程暂时换出外存，把外存中某些已具备运行条件的进程**换入**内存（进程在内存与磁盘间动态调度)
- 暂时换出外存等待的进程状态为**挂起状态**（挂起态，suspend)
- 挂起态又可以进一步细分为**就绪挂起、阻塞挂起**两种状态
- 1．具有对换功能的操作系统中，通常把磁盘空间分为**文件区和对换区**两部分。**文件区**主要用于存放文件，**主要追求存储空间的利用率**，因此对文件区空间的管理**采用离散分配方式**;**对换区**空间只占磁盘空间的小部分，**被换出的进程数据就存放在对换区**。由于对换的速度直接影响到系统的整体速度，因此对换区空间的管理**主要追求换入换出速度**，因此通常对换区**采用连续分配方式**（学过文件管理章节后即可理解）。总之，**对换区的I/o速度比文件区的更快。**
- 2．交换通常在许多进程运行且内存吃紧时进行，而系统负荷降低就暂停。例如:在发现许多进程运行时经常发生缺页，就说明内存紧张，此时可以换出一些进程;如果缺页率明显下降，就可以暂停换出。
- 3.可优先换出阻塞进程;可换出优先级低的进程;为了防止优先级低的进程在被调入内存后很快又被换出，有的系统还会考虑进程在内存的驻留时间.**.(注意:PCB会常驻内存，不会被换出外存)**
### 总结
![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391016000-3d8c9631-ef5f-4a80-9c6c-57e29e467360.png#averageHue=%23c5c2bf&clientId=u11b08f95-75c2-4&from=paste&id=ua66e58de&originHeight=664&originWidth=1343&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=u77da76dc-fe94-4053-bd31-125f7f99f8f&title=)
## 3.1.4 连续分配管理方式
### 单一连续分配

- **连续分配**:指为用户进程分配的必须是一**个连续的内存空间。**
- 在单一连续分配方式中，内存被分**为系统区和用户区**。系统区通常位于内存的低地址部分，用于存放操作系统相关数据;用户区用于存放用户进程相关数据。内存中**只能有一道用户程序**，用户程序独占整个用户区空间。
- **优点**:实现简单;无外部碎片;可以采用覆盖技术扩充内存;不一定需要采取内存保护（eg:早期的PC操作系统MS-DOS) 。
- **缺点**:只能用于单用户、单任务的操作系统中;**有内部碎片;**存储器利用率极低。
### 固定分区分配

- 20世纪60年代出现了支持多道程序的系统，为了能在内存中装入多道程序，且这些程序之间又不会相互干扰，于是将整个**用户空间**划分为若干个**固定大小的分区**，**在每个分区中只装入一道作业**，这样就形成了最早的、最简单的一种可运行多道程序的内存管理方式。
   - 分区大小相等
   - 分区大小不等

![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391016009-8cd7be9f-5fc8-4d89-bd8c-af44f04c3206.png#averageHue=%23a2ad6e&clientId=u11b08f95-75c2-4&from=paste&id=u01520cf7&originHeight=637&originWidth=550&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=u2108aea7-6950-4e27-8eae-fa860c78100&title=)

- 操作系统需要建立一个数据结构――**分区说明表**，来实现各个分区的分配与回收。每个表项对应一个分区，通常按分区大小排列。每个表项包括对应**分区的大小、起始地址、状态（是否已分配）。**

![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391016063-80246673-1410-4068-859d-3effa2704ff4.png#averageHue=%23c5d5e7&clientId=u11b08f95-75c2-4&from=paste&id=u59c78973&originHeight=263&originWidth=811&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=ud8bd4068-dd78-46c3-b5ed-11aa14865cc&title=)

- 优点:实现简单，**无外部碎片。**
- 缺点: 
   - a.当用户程序太大时，可能所有的分区都不能满足需求，此时不得不采用覆盖技术来解决，但这又会降低性能; 
   - b**.会产生内部碎片**，内存利用率低。
### 动态分区分配

- **动态分区分配**又称为**可变分区分配**。这种分配方式**不会预先划分内存分区**，而是在进程装入内存时,**根据进程的大小动态地建立分区**，并使分区的大小正好适合进程的需要。因此系统分区的大小和数目是可变的。(eg:假设某计算机内存大小为64MB，系统区8MB，用户区共56 MB.….)
- 动态分区分配**没有内部碎片，但是有外部碎片。**
   - **内部碎片**，分配给某进程的内存区域中，如果有些部分没有用上。
   - **外部碎片**，是指内存中的某些空闲分区由于太小而难以利用。
   - 如果内存中空闲空间的总和本来可以满足某进程的要求，但由于进程需要的是一整块连续的内存空间，因此这些“碎片”不能满足进程的需求。可以通过**紧凑（拼凑，Compaction）技术**来解决外部碎片。

![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391016159-a9ba7580-5a1c-4547-9493-88b92357b57d.png#averageHue=%2387ab65&clientId=u11b08f95-75c2-4&from=paste&id=u3ff69395&originHeight=625&originWidth=1074&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=u3ffcfc46-50ff-43ff-b2ca-656c60666d2&title=)

- 把一个新作业装入内存时，须按照一定的**动态分区分配算法**，从空闲分区表（或空闲分区链）中选出一个分区分配给该作业。由于分配算法算法对系统性能有很大的影响，因此人们对它进行了广泛的研究。
### 总结
![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391016535-831bab34-d87f-4c25-8815-fbc198cb87fe.png#averageHue=%23adc198&clientId=u11b08f95-75c2-4&from=paste&id=u3a1af959&originHeight=731&originWidth=1449&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=u37bfe8dc-7d6b-42ab-a261-d36fa89b9dc&title=)
## 3.1.5 动态分区分配算法
### 首次适应算法

- **算法思想**:每次都从低地址开始查找，找到第一个能满足大小的空闲分区。
- 如何实现:**空闲分区以地址递增的次序排列。**每次分配内存时**顺序查找**空闲分区链（或空闲分区表)，找到大小能满足要求的第一个空闲分区。
### 最佳适应算法

- **算法思想**:由于动态分区分配是一种连续分配方式，为各进程分配的空间必须是连续的一整片区域。因此为了保证当“大进程”到来时能有连续的大片空间，可以尽可能多地留下大片的空闲区，即，优先使用更小的空闲区。
- 如何实现:空闲分区**按容量递增次序链接**。每次分配内存时**顺序查找**空闲分区链(或空闲分区表），找到大小能满足要求的第一个空闲分区。
- **缺点:**每次都选最小的分区进行分配，会留下越来越多的、很小的、难以利用的内存块。因此这种方法会产生很多的外部碎片。
### 最坏（大）适应算法

- 又称**最大适应算法(Largest Fit)**
- **算法思想**:为了解决最佳适应算法的问题――即留下太多难以利用的小碎片，可以在每次分配时优先使用最大的连续空闲区，这样分配后剩余的空闲区就不会太小，更方便使用。
- 如何实现:空闲分区**按容量递减次序链接**。每次分配内存时**顺序查找**空闲分区链（或空闲分区表），找到大小能满足要求的第一个空闲分区。
- **缺点:**每次都选最大的分区进行分配，虽然可以让分配后留下的空闲区更大，更可用，但是这种方式会导致较大的连续空闲区被迅速用完。如果之后有“大进程”到达，就没有内存分区可用了。
### 邻近适应算法

- **算法思想**:首次适应算法每次都从链头开始查找的。这可能会导致低地址部分出现很多小的空闲分区，而每次分配查找时，都要经过这些分区，因此也增加了查找的开销。如果每次都从上次查找结束的位置开始检索，就能解决上述问题。
- 如何实现:空闲分区**以地址递增的顺序排列**（可排成一个循环链表)）。每次分配内存时**从上次查找结束的位置开始查找**空闲分区链（或空闲分区表)，找到大小能满足要求的第一个空闲分区。
### 总结
![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391016662-017a2673-061f-46d2-869f-2cc608c38049.png#averageHue=%23cad5e3&clientId=u11b08f95-75c2-4&from=paste&id=u27c9b6f8&originHeight=712&originWidth=1407&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=u286ed862-ba29-4e97-8782-45560d316ad&title=)
## 3.1.6 基本分页存储管理的基本概念
### 基本概念

- 将内存空间分为一个个**大小相等的分区**（比如:每个分区4KB），每个分区就是一个**“页框”，或称“页帧”、“内存块”、“物理块”。**每个页框有一个编号，即**“页框号”(或者“内存块号”、“页帧号”、“物理块号”)**页框号**从o开始。**
- 将用户进程的地址空间也分为**与页框大小相等**的一个个区域，**称为“页”或“页面”。**每个页面也有一个编号，即**“页号”**，页号也是**从o开始**。（注:进程的最后一个页面可能没有一个页框那么大。因此，**页框不能太大，否则可能产生过大的内部碎片)**
- 操作系统**以页框为单位为各个进程分配内存**空间。进程的每个页面分别放入一个页框中。也就是说，进程的**页面与内存的页框有一一对应的关系。**
- 各个页面**不必连续存放**，也**不必按先后顺序来**，可以放到不相邻的各个页框中。
### 如何实现地址转换

- 1．要算出逻辑地址对应的**页号**
- 2．要知道该页号对应**页面在内存中的起始地址**
- 3．要算出逻辑地址在**页面内的“偏移量”**
- 4．**物理地址=页面始址＋页内偏移量**
- 如何计算：
   - **页号**=逻辑地址/页面长度(取除法的**整数**部分)
   - **页内偏移量=**逻辑地址%页面长度
      - （取除法的余数部分)页面在内存中的起始位置:操作系统需要用某种数据结构记 进程各个页面的起始位置。
### 逻辑地址结构

- 分页存储管理的**逻辑地址结构**如下所示:

![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391016775-d76268f8-bf02-44a4-a610-619328d03135.png#averageHue=%23f3fcfe&clientId=u11b08f95-75c2-4&from=paste&id=u162c052b&originHeight=134&originWidth=1131&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=ud1aff582-93c1-448e-9e4d-9dc73ac1127&title=)

- 地址结构包含两个部分:前一部分为页号，后一部分为页内偏移量w。在上图所示的例子中，地址长度为32位，其中0~11位为**“页内偏移量”**，或称**“页内地址**”;12-31位为**“页号”。**
- **如果有K位表示“页内偏移量”，则说明该系统中一个页面的大小是2^k个内存单元**
- **如果有M位表示“页号”，则说明在该系统中，一个进程最多允许有2^M个页面**
### 页表

- 1.一个进程对应一张页表
- 2．进程的每一页对应一个页表项
- 3．每个**页表项**由“页号”和“块号”组成
- 4．页表记录**进程页面和实际存放的内存块之间的对应关系**
- 5．每个页表项的长度是相同的**，页号是“隐含”的**

![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391016785-b8c52fb7-96a9-40a1-8d39-61fdb2d976f9.png#averageHue=%23f3f1f1&clientId=u11b08f95-75c2-4&from=paste&id=u61d6f0ed&originHeight=687&originWidth=1390&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=ua1d1d65f-cdbb-42e9-bd11-f32fe8cb05b&title=)
### 总结
![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391016903-afdc2bed-2da0-47ce-a3b0-984fb0a9a85f.png#averageHue=%23d4d3d0&clientId=u11b08f95-75c2-4&from=paste&id=u3e2ce4ce&originHeight=739&originWidth=1508&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=ud4bba45f-d443-4f5a-8499-b8422eba1d6&title=)
## 3.1.7 基本地址变换机构
### 变换机构

- 基本地址变换机构可以借助进程的页表将逻辑地址转换为物理地址。
- 通常会在系统中设置一个**页表寄存器（PTR）**，存放页表在内存中的起始地址F和页表长度M。
- 进程未执行时，页表的始址和页表长度**放在进程控制块（PCB）**中，当进程被调度时，操作系统内核会把它们放到页表寄存器中。
- 设页面大小为L，逻辑地址A到物理地址E的变换过程如下:

![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391017145-5db78c99-07ec-4fd2-8925-a64c03fbcee8.png#averageHue=%23a5b279&clientId=u11b08f95-75c2-4&from=paste&id=u80df6533&originHeight=835&originWidth=1617&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=u61109077-2d92-472b-b072-72a40e97cb1&title=)

- ①**计算页号Р和页内偏移量w**（如果用十进制数手算，则P=A/L，W=A%L;但是在计算机实际运行时，逻辑地址结构是固定不变的，因此计算机硬件可以更快地得到二进制表示的贝亏、贝内偏移量)
- ②**比较页号P和页表长度M**，若P≥M，则产生越界中断，否则继续执行。(注意:页号是从O开始的，而页表长度至少是1，因此P=M时也会越界)
- ③页表中页号p对应的**页表项地址=页表起始地址F+页号p*页表项长度**，取出该页表项内容b，即为内存块号。
   - (注意区分**页表项长度、页表长度、页面大小的区别**。页表长度指的是这个贝表中总共有几个页表项，即总共有几个页;页表项长度指的是每个页表项占多大的存储空间;页面大小指的是一个页面占多大的存储空间)
- ④**计算E= b*L+w**，用得到的物理地址E去访存。(如果内存块号、页面偏移量是用二进制表示的，那么把二者拼接起来就是最终的物理地址了)

例题：
![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391017253-caca8c3d-c635-486e-8311-e388263f64b6.png#averageHue=%23f2f1f1&clientId=u11b08f95-75c2-4&from=paste&id=ucb8c67e1&originHeight=619&originWidth=1358&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=uff487176-1711-4d00-ae00-08ec9425379&title=)
### 总结
![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391017607-4e6e8c06-07e3-4852-98fe-4d6a8d059d72.png#averageHue=%23acb99a&clientId=u11b08f95-75c2-4&from=paste&id=ue3377d89&originHeight=715&originWidth=1536&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=u15193100-e0fb-4855-affe-564cfb67fa7&title=)
## 3.1.8 具有快表的地址变换机构
### 局部性原理

- **时间局部性:**如果执行了程序中的某条指令，那么不久后这条指令很有可能再次执行;如果某个数据被访问过，不久之后该数据很可能再次被访问。(因为程序中存在大量的循环)
- **空间局部性:**一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也很有可能被访问。(因为很多数据在内存中都是连续存放的)
### 什么是快表（TLB）

- **快表，又称联想寄存器(TLB）**，是一种访问速度**比内存快很多**的高速缓冲存储器，用来存放当前访问的若干页表项，以加速地址变换的过程。与此对应，**内存中的页表常称为慢表。**

![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391017772-2017c132-f16d-4b1f-9167-f6c683788168.png#averageHue=%23acbd8b&clientId=u11b08f95-75c2-4&from=paste&id=uee18379b&originHeight=864&originWidth=1533&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=ue36d2918-777d-4592-a95a-f616d992905&title=)
### 引入快表后的变换过程

- ①CPU给出逻辑地址，由某个硬件算得页号、页内偏移量，将页号与快表中的所有页号进行比较。
- ②如果找到匹配的页号，说明要访问的页表项在快表中有副本，则直接从中取出该页对应的内存块号，再将内存块号与页内偏移量拼接形成物理地址，最后，访问该物理地址对应的内存单元。**因此,若快表命中，则访问某个逻辑地址仅需一次访存即可。**
- ③如果没有找到匹配的页号，则**需要访问内存中的页表**，找到对应页表项，得到页面存放的内存块号，再将内存块号与页内偏移量拼接形成物理地址，最后，访问该物理地址对应的内存单元。因此，**若快表未命中，则访问某个逻辑地址需要两次访存**（注意:在找到页表项后,应同时将其存入快表,以便后面可能的再次访问。但若快表已满，则必须按照一定的算法对旧的页表项进行替换)
### 总结
![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391017773-06e93be6-6638-4d6f-9eff-3d924dcec795.png#averageHue=%23c3d2e3&clientId=u11b08f95-75c2-4&from=paste&id=u016f328e&originHeight=612&originWidth=1436&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=u19e52fb9-16da-4ca6-8b15-7cf72ab2f63&title=)
## 3.1.9 两级页表
### 单机页表存在的问题

- 问题一:页表必须连续存放，因此当页表很大时，需要占用很多个连续的页框。
- 问题二:没有必要让整个页表常驻内存，因为进程在一段时间内可能只需要访问某几个特定的页面。
### 二级页表的结构
![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391017909-17a9c218-3d3b-4750-b9fe-4787f05839f1.png#averageHue=%23f3e6e0&clientId=u11b08f95-75c2-4&from=paste&id=u626564e7&originHeight=772&originWidth=1543&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=ud78783c1-7069-4fa7-8108-989f33243e0&title=)
### 地址变换
![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391017984-d4fc6166-d2b4-4f51-9d4c-b46c8e220cb8.png#averageHue=%23efe7e4&clientId=u11b08f95-75c2-4&from=paste&id=u6c7d334c&originHeight=621&originWidth=1497&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=udb45df92-9e10-4f33-8825-4ee5bb69597&title=)
### 虚拟内存

- 可以在需要访问页面时才把页面调入内存（虚拟存储技术）。可以在页表项中增加一个标志位，用于表示该页面是否已经调入内存

![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391018321-7315f48f-f8ca-4ecb-b6d5-4884ce0e8899.png#averageHue=%23d6b9ac&clientId=u11b08f95-75c2-4&from=paste&id=u892446eb&originHeight=337&originWidth=900&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=u8e6df311-0a9a-4dcc-be84-040e5f9b7d0&title=)
### 需要注意的细节

- 若采用多级页表机制，则各级页表的大小不能超过一个页面

例：
![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391018639-6ff100bb-df21-4c62-ba55-53dfb24b8925.png#averageHue=%23f1eae7&clientId=u11b08f95-75c2-4&from=paste&id=u72e692a9&originHeight=642&originWidth=1382&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=ucfe689ef-07aa-4788-a70d-17273ab031c&title=)

- 两级页表的访存次数
   - 第一次访存:访问内存中的页目录表
   - 第二次访存:访问内存中的二级页表
   - 第三次访存:访问目标内存单元
### 总结
![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391018654-a0c54dcc-96d4-47a4-b15f-97d82e361080.png#averageHue=%23a7b893&clientId=u11b08f95-75c2-4&from=paste&id=u4b1e2810&originHeight=693&originWidth=1584&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=ufba17936-ebb5-4c45-86b1-62b8e62c31a&title=)
## 3.1.10 基本分段存储管理方式
### 分段

- 进程的地址空间:按照程序**自身的逻辑**关系**划分为若干个段**，每个段都有一个段名(在低级语言中，程序员使用段名来编程)，**每段从0开始编址**
- 内存分配规则:以段为单位进行分配，**每个段在内存中占据连续空间**，但**各段之间可以不相邻。**

![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391018667-c3a4ed4b-bd5e-4149-8cc8-2712c66c74a2.png#averageHue=%23f1e3db&clientId=u11b08f95-75c2-4&from=paste&id=u9dddf745&originHeight=571&originWidth=1473&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=uf4d10aba-ce0f-4c0c-8bd4-55ac7b62d00&title=)

- 段号的位数决定了每个进程最多可以分几个段
- 段内地址位数决定了每个段的最大长度是多少
### 段表

- 程序分多个段，各段离散地装入内存，为了保证程序能正常运行，就必须能从物理内存中找到各个逻辑段的存放位置。为此，需为每个进程建立一张段映射表，简称**“段表”。**
- 每个段对应一个段表项，其中记录了该段在内存中的**起始位置（又称“基址”）**和**段的长度**。
- **各个段表项的长度是相同的**。例如:某系统按字节寻址，采用分段存储管理，逻辑地址结构为（段号16位,段内地址16位)，因此用16位即可表示最大段长。物理内存大小为4GB（可用32位表示整个物理内存地址空间)。因此，可以让每个段表项占16+32= 48位，即6B。由于**段表项长度相同，因此段号可以是隐含的**，不占存储空间。若段表存放的起始地址为M，则K号段对应的段表项存放的地址为M+K*6
### 地址变换
![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391018889-2b009d43-184e-46d1-b124-e5c767e5ec5d.png#averageHue=%239baf71&clientId=u11b08f95-75c2-4&from=paste&id=u85d973cb&originHeight=912&originWidth=1582&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=u40831250-726c-44ac-ac13-d685b8ffdaa&title=)
### 分段分页对比

- **页是信息的物理单位。**分页的主要目的是为了实现离散分配，提高内存利用率。分页仅仅是系统管理上的需要，完全是系统行为，对**用户是不可见的。**
- **段是信息的逻辑单位。**分段的主要目的是更好地满足用户需求。一个段通常包含着一组属于一个逻辑模块的信息。**分段对用户是可见**的，用户编程时需要显式地给出段名。
- 页的大小固定且由系统决定。段的长度却不固定，决定于用户编写的程序。
- **分页**的用户进程地址空间**是一维的**，程序员只需给出一个记忆符即可表示一个地址。
- **分段**的用户进程地址空间**是二维的**，程序员在标识一个地址时，既要给出段名，也要给出段内地址。
- **分段**比分页**更容易实现信息的共享和保护。**
### 总结
![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391019195-a041aa85-9bfe-46ec-bd03-b67621e37971.png#averageHue=%23cbc8c5&clientId=u11b08f95-75c2-4&from=paste&id=u7616c6ad&originHeight=722&originWidth=1534&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=ud4e72537-e696-461d-bd6a-eb9252ad028&title=)
## 3.1.11 段页式管理
### 分段、分页优缺点
![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391019434-581a2aea-604f-42d5-a0bc-6b9bef6e6df5.png#averageHue=%23b5c6d9&clientId=u11b08f95-75c2-4&from=paste&id=u3f5bb9f2&originHeight=237&originWidth=1396&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=u1989691d-49b6-48c3-99f5-86ef522ea88&title=)
### 分段+分页=段页式管理
![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391019572-923ab9e3-0eaa-4d44-bcbf-4d01fec6d640.png#averageHue=%23cd8d5c&clientId=u11b08f95-75c2-4&from=paste&id=ub10ba828&originHeight=690&originWidth=1424&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=uc97631e4-d4c1-4e5f-9f41-eeb4f6272d7&title=)
![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391019620-04a2008b-9745-4bde-979d-9b21c252bfdd.png#averageHue=%237aa9d4&clientId=u11b08f95-75c2-4&from=paste&id=ue8cc28ec&originHeight=128&originWidth=1143&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=u16a42211-edea-4d99-bb08-3c98e78c546&title=)

- **段号的位数决定了每个进程最多可以分几个段**
- **页号位数决定了每个段最大有多少页**
- **页内偏移量决定了页面大小、内存块大小是多少**
- 每个段对应一个段表项，每个段表项由**段号、页表长度、页表存放块号(页表起始地址）组成**。每个段表项长度相等，段号是隐含的。
- 每个页面对应一个页表项，每个页表项由页号、页面存放的内存块号组成。每个页表项长度相等，页号是隐含的。

![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391019793-9a24d90a-dca8-4781-94bc-2c21303d01da.png#averageHue=%2390b270&clientId=u11b08f95-75c2-4&from=paste&id=ud85ba581&originHeight=864&originWidth=1626&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=u58cb159d-8979-4b89-a2a5-fd65c3d86ba&title=)
### 总结
![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391020168-281cf846-bf8a-49c7-97bb-096f361ee94e.png#averageHue=%23c9c5c0&clientId=u11b08f95-75c2-4&from=paste&id=u5bba6fb2&originHeight=804&originWidth=1518&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=ufd7878c7-3931-4c7f-8a11-701b2a15ba3&title=)
## 3.2.1 虚拟内存的基本概念
### 传统存储管理方式的特征、缺点
![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391020168-2a6d3b83-9724-4ffa-819f-df3da1b3e9fa.png#averageHue=%23cbc8c5&clientId=u11b08f95-75c2-4&from=paste&id=uc7cf319d&originHeight=448&originWidth=991&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=u99f37388-e6dc-425b-96de-d1d4846fc8a&title=)

- **一次性:作业必须一次性全部装入内存后才能开始运行。**这会造成两个问题:
   - ①作业很大时，不能全部装入内存，导致**大作业无法运行**;
   - ②当大量作业要求运行时，由于内存无法容纳所有作业，因此只有少量作业能运行，**导致多道程序并发度下降。**
- **驻留性**:一旦作业被装入内存，就会**一直驻留在内存中**，直至作业运行结束事实上，在一个时间段内，只需要访问作业的一小部分数据即可正常运行，这就导致了内存中会驻留大量的、暂时用不到的数据，浪费了宝贵的内存资源。
### 局部性原理

- **时间局部性**:如果执行了程序中的某条指令，那么不久后这条指令很有可能再次执行;如果某个数据被访问过，不久之后该数据很可能再次被访问。(（因为程序中存在大量的循环)
- **空间局部性**:一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也很有可能被访问。(因为很多数据在内存中都是连续存放的，并且程序的指令也是顺序地在内存中存放的)
### 虚拟内存的定义和特征
![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391020391-6f1c841a-dda7-4dd4-9726-242037aef5e2.png#averageHue=%23cccccb&clientId=u11b08f95-75c2-4&from=paste&id=u9128d222&originHeight=362&originWidth=587&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=ud67c6417-329e-44c4-9eac-dead0a60dfc&title=)

- **高速缓冲技术的思想**:将近期会频繁访问到的数据放到更高速的存储器中，暂时用不到的数据放在更低速存储器中。
- 基于局部性原理，在程序装入时，可以将程序中**很快会用到的部分装入内存，暂时用不到的部分留在外存**，就可以让程序开始执行。在程序执行过程中，当**所访问的信息不在内存时**，由**操作系统**负责**将所需信息从外存调入内存，然后继续执行程序**。
- 若内存空间不够，由**操作系统**负责将内存中**暂时用不到的信息换出到外存**。在操作系统的管理下，在用户看来似乎有一个比实际内存大得多的内存，这就是**虚拟内存**
- 虚拟内存的三个主要特征：
   - **多次性**:无需在作业运行时一次性全部装入内存，而是允许被分成多次调入内存。
   - **对换性**:在作业运行时无需一直常驻内存，而是允许在作业运行过程中，将作业换入、换出。
   - **虚拟性**:从逻辑上扩充了内存的容量，使用户看到的内存容量，远大于实际的容量。
### 如何实现虚拟内存技术

- 虚拟内存技术，允许一个作业分多次调入内存。如果采用连续分配方式，会不方便实现。因此，虚拟内存的实现需要建立在**离散分配**的内存管理方式基础上。
- 传统的非连续分配存储管理：
   - 基本分页存储管理
   - 基本分段存储管理
   - 基本段页式存储管理
- 虚拟内存的实现：
   - 请求分页存储管理
   - 请求分段存储管理
   - 请求段页式存储管理
- 主要区别:
   - **请求调页（调段）：**在程序执行过程中，当**所访问的信息不在内存时，由操作系统负责将所需信息从外存调入内存**，然后继续执行程序。
   - **页面置换（段置换）**：若内存空间不够，**由操作系统负责将内存中暂时用不到的信息换出到外存。**
### 总结
![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391020477-03276c89-39f3-4863-850f-a3d886a05bf8.png#averageHue=%23cbc8c6&clientId=u11b08f95-75c2-4&from=paste&id=u0c5e1580&originHeight=748&originWidth=1627&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=ue98676cc-cf91-4cdc-a8ca-8974474021b&title=)
## 3.2.2 请求分页管理方式
### 页表机制
![](https://cdn.nlark.com/yuque/0/2023/png/35951671/1684391020704-1b4421b7-6419-4a64-8d28-40ab093c6cf6.png#averageHue=%23a5be8b&clientId=u11b08f95-75c2-4&from=paste&id=u223932d1&originHeight=427&originWidth=1504&originalType=url&ratio=1.1041666269302368&rotation=0&showTitle=false&status=done&style=none&taskId=ufab253af-20e2-4812-aca8-081cd6b65fe&title=)
### 缺页中断机构

- 在请求分页系统中，每当要访问的**页面不在内存时**，便产生一个**缺页中断**，然后由操作系统的缺页**中断处理程序处理中断**。此时**缺页的进程阻塞**，放入阻塞队列，调页**完成后再将其唤醒**，放回就绪队列。
- 如果内存中**有空闲块**，则为进程**分配一个空闲块**，将所缺页面装入该块，并修改页表中相应的页表项。
- 如果内存中**没有空闲块**，则**由页面置换算法选择一个页面淘汰**，若该页面在内存期间**被修改过**，则要将其**写回外存**。未修改过的页面不用写回外存。
- **缺页中断**是因为当前执行的指令想要访问的目标页面未调入内存而产生的，因此**属于内中断**
- **一条指令**在执行期间，可能产生**多次缺页中断**。(如: copy A to B，即将逻辑地址A中的数据复制到逻辑地址B，而A、B属于不同的页面，则有可能产生两次中断)

[1.pdf](https://www.yuque.com/attachments/yuque/0/2023/pdf/35951671/1684391298890-d8ff22de-63d1-4039-860f-283b6d3b3753.pdf)
